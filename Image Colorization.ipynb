{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1623226095715,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "s8G1TkWjfkro",
    "outputId": "12d43508-afbb-4e34-a971-0c66fc0d1083"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/drive\")\n",
    "data_path = 'C:/Users/Nil/Desktop/Final Project/'\n",
    "#results_path = '/content/drive/My Drive/DeepLearning_2021/P3/Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22539,
     "status": "ok",
     "timestamp": 1623226120802,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "iGNpax-brHmz"
   },
   "outputs": [],
   "source": [
    "# Move data into training and validation directories\n",
    "import os\n",
    "os.makedirs(data_path +'images/train/class/', exist_ok=True) # 40,000 images\n",
    "os.makedirs(data_path +'images/val/class/', exist_ok=True)   #  1,000 images\n",
    "for i, file in enumerate(os.listdir(data_path + 'resized_images')):\n",
    "  if i < 1000: # first 1000 will be val\n",
    "    os.rename(data_path +'resized_images/' + file, data_path + 'images/val/class/' + file)\n",
    "  else: # others will be val\n",
    "    if i==16000:\n",
    "      break\n",
    "    os.rename(data_path + 'resized_images/' + file, data_path + 'images/train/class/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1623226292391,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "rRoQxRmuWqnG",
    "outputId": "fa224f44-16aa-4cd8-e31b-55b9fc2e202e"
   },
   "outputs": [],
   "source": [
    "# Make sure the images are there\n",
    "from IPython.display import Image, display\n",
    "#display(Image(filename=data_path+'images/train/class/0a0c8dd61636ca8615ac11bb26907f74.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "executionInfo": {
     "elapsed": 18528,
     "status": "ok",
     "timestamp": 1623225862814,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "22M-YyqczLMZ",
    "outputId": "edd4416d-ef0a-4b75-b26e-5ce8512d80d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1623226304662,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "J_Y9UFYhKbuE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# For conversion\n",
    "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
    "#from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "#import torchvision.models as models\n",
    "from torchvision import transforms, models, datasets\n",
    "# For utilities\n",
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1623226307611,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "gMolrzKA_1uJ"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# Device configuration (choose GPU if it is available )\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1623226310037,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "NOQfP1feNkfS"
   },
   "outputs": [],
   "source": [
    "class ColorizationNet(nn.Module):\n",
    "  def __init__(self, input_size=128):\n",
    "    super(ColorizationNet, self).__init__()\n",
    "    MIDLEVEL_FEATURE_SIZE = 128\n",
    "\n",
    "    ## First half: ResNet\n",
    "    resnet = models.resnet18(num_classes=365) \n",
    "    # Change first conv layer to accept single-channel (grayscale) input\n",
    "    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1)) \n",
    "    # Extract midlevel features from ResNet-gray\n",
    "    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])\n",
    "\n",
    "    ## Second half: Upsampling\n",
    "    self.upsample = nn.Sequential(     \n",
    "      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.Upsample(scale_factor=2),\n",
    "      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n",
    "      nn.Upsample(scale_factor=2)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "\n",
    "    # Pass input through ResNet-gray to extract features\n",
    "    midlevel_features = self.midlevel_resnet(input)\n",
    "\n",
    "    # Upsample to get colors\n",
    "    output = self.upsample(midlevel_features)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1623226313258,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "OtRkAkIjTeq1"
   },
   "outputs": [],
   "source": [
    "model = ColorizationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1623226314773,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "1PU0wtkPRasL"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1623226315660,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "j3YZ3977TTl4"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1623226317023,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "05NviQfzU2Mv"
   },
   "outputs": [],
   "source": [
    "class GrayscaleImageFolder(datasets.ImageFolder):\n",
    "  '''Custom images folder, which converts images to grayscale before loading'''\n",
    "  def __getitem__(self, index):\n",
    "    path, target = self.imgs[index]\n",
    "    img = self.loader(path)\n",
    "    if self.transform is not None:\n",
    "      img_original = self.transform(img)\n",
    "      img_original = np.asarray(img_original)\n",
    "      img_lab = rgb2lab(img_original)\n",
    "      img_lab = (img_lab + 128) / 255\n",
    "      img_ab = img_lab[:, :, 1:3]\n",
    "      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
    "      img_original = rgb2gray(img_original)\n",
    "      img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n",
    "    if self.target_transform is not None:\n",
    "      target = self.target_transform(target)\n",
    "    return img_original, img_ab, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1623226320588,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "dmG6NAhdVNWw"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip()])\n",
    "train_imagefolder = GrayscaleImageFolder(data_path+'images/train/', train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=128, shuffle=True)\n",
    "\n",
    "# Validation \n",
    "val_transforms = transforms.Compose([transforms.Resize(128), transforms.CenterCrop(224)])\n",
    "val_imagefolder = GrayscaleImageFolder(data_path+'images/val/' , val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1623226323196,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "2FDRt12jsIkr"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "  '''Show/save rgb image from grayscale and ab channels\n",
    "     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "  plt.clf() # clear matplotlib \n",
    "  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n",
    "  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n",
    "  color_image = lab2rgb(color_image.astype(np.float64))\n",
    "  grayscale_input = grayscale_input.squeeze().numpy()\n",
    "  if save_path is not None and save_name is not None: \n",
    "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNoVCs_DriXu"
   },
   "source": [
    "#### Validation\n",
    "\n",
    "In validation, we simply run model without backpropagation using `torch.no_grad`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1623226326521,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "M_OTbyOcrh9J"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, save_images, epoch):\n",
    "  model.eval()\n",
    "\n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  already_saved_images = False\n",
    "  for i, (input_gray, input_ab, target) in enumerate(val_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Use GPU\n",
    "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
    "\n",
    "    # Run model and record loss\n",
    "    output_ab = model(input_gray) # throw away class predictions\n",
    "    loss = criterion(output_ab, input_ab)\n",
    "    losses.update(loss.item(), input_gray.size(0))\n",
    "\n",
    "    # Save images to file\n",
    "    if save_images and not already_saved_images:\n",
    "      already_saved_images = True\n",
    "      for j in range(min(len(output_ab), 10)): # save at most 5 images\n",
    "        save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}\n",
    "        save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)\n",
    "        to_rgb(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
    "\n",
    "    # Record time to do forward passes and save images\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to both value and validation\n",
    "    if i % 25 == 0:\n",
    "      print('Validate: [{0}/{1}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "  print('Finished validation.')\n",
    "  return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1623226329315,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "FOo__iEnvLMB"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "  print('Starting training epoch {}'.format(epoch))\n",
    "  model.train()\n",
    "  \n",
    "  # Prepare value counters and timers\n",
    "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "\n",
    "  end = time.time()\n",
    "  for i, (input_gray, input_ab, target) in enumerate(train_loader):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
    "\n",
    "    # Record time to load data (above)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # Run forward pass\n",
    "    output_ab = model(input_gray) \n",
    "    loss = criterion(output_ab, input_ab) \n",
    "    losses.update(loss.item(), input_gray.size(0))\n",
    "\n",
    "    # Compute gradient and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record time to do forward and backward passes\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
    "    if i % 25 == 0:\n",
    "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "              epoch, i, len(train_loader), batch_time=batch_time,\n",
    "             data_time=data_time, loss=losses)) \n",
    "\n",
    "  print('Finished training epoch {}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2991,
     "status": "ok",
     "timestamp": 1623226335520,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "eeHK3BUtANrw"
   },
   "outputs": [],
   "source": [
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "  criterion = criterion.cuda()\n",
    "  model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1623227238353,
     "user": {
      "displayName": "IRINA KIREEVA",
      "photoUrl": "",
      "userId": "15104397793248174644"
     },
     "user_tz": -120
    },
    "id": "ckNmKA5VwSh1"
   },
   "outputs": [],
   "source": [
    "# Make folders and set parameters\n",
    "os.makedirs(data_path+'outputs/color', exist_ok=True)\n",
    "os.makedirs(data_path+'outputs/gray', exist_ok=True)\n",
    "os.makedirs(data_path+'checkpoints', exist_ok=True)\n",
    "save_images = True\n",
    "best_losses = 0.4\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUR6ALi3AZoO",
    "outputId": "641e39e7-5c84-49e9-ff6e-da74ad891c26"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "  # Train for one epoch, then validate\n",
    "  train(train_loader, model, criterion, optimizer, epoch)\n",
    "  with torch.no_grad():\n",
    "    losses = validate(val_loader, model, criterion, save_images, epoch)\n",
    "  # Save checkpoint and replace old best model if current model is better\n",
    "  if losses < best_losses:\n",
    "    best_losses = losses\n",
    "    torch.save(model.state_dict(), data_path+'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnrbjYF39wRO"
   },
   "outputs": [],
   "source": [
    "# Show images \n",
    "import matplotlib.image as mpimg\n",
    "image_pairs = [('outputs/color/img-2-epoch-0.jpg', 'outputs/gray/img-2-epoch-0.jpg'),\n",
    "               ('outputs/color/img-7-epoch-0.jpg', 'outputs/gray/img-7-epoch-0.jpg')]\n",
    "for c, g in image_pairs:\n",
    "  color = mpimg.imread(c)\n",
    "  gray  = mpimg.imread(g)\n",
    "  f, axarr = plt.subplots(1, 2)\n",
    "  f.set_size_inches(15, 15)\n",
    "  axarr[0].imshow(gray, cmap='gray')\n",
    "  axarr[1].imshow(color)\n",
    "  axarr[0].axis('off'), axarr[1].axis('off')\n",
    "  plt.show()\n",
    "\n",
    "'''cap= cv2.VideoCapture('C:/Users/Nil/Desktop/Final Project/video/first.mp4')\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('kang'+str(i)+'.jpg',frame)\n",
    "    cv2.resize('kang'+str(i)+'.jpg',(256,256))\n",
    "    i+=1\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Image Colorization.ipynb",
   "provenance": [
    {
     "file_id": "1r45y6bnxT1d8qUe5YDovWYUbfX1hMnAz",
     "timestamp": 1623185034024
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
